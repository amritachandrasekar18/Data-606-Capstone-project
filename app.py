# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15bSaGyrgwovvO0St0ByGDLVf5ArzA3Oy
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import gdown  # For downloading files from Google Drive
import os  # For handling file paths

# Google Drive file links
FILE_LINKS = {
    "X_train": "https://drive.google.com/uc?id=1iberDE0Lg9IZWMPCMmKXjJ4LgPokSyjm",
    "X_test": "https://drive.google.com/uc?id=1-mIMEAq4bOpLJNbt8DSfysMEvLyKSQKd",
    "y_test": "https://drive.google.com/uc?id=1UEhal_P-mHdfVCtqWJF07XBjHq9G5pca",
    "model": "https://drive.google.com/uc?id=12hER93fGFtl47CvX4SsPA-ECghT5kiZS"
}

# Function to download files
def download_file(url, output_path):
    if not os.path.exists(output_path):  # Download only if file doesn't already exist
        gdown.download(url, output_path, quiet=False)

# Paths for local storage
LOCAL_FILES = {
    "X_train": "X_train_top.csv",
    "X_test": "X_test_top.csv",
    "y_test": "y_test.csv",
    "model": "lightgbm_fraud_model.pkl"
}

# Download datasets and model
for key, url in FILE_LINKS.items():
    download_file(url, LOCAL_FILES[key])

# Load datasets
X_train = pd.read_csv(LOCAL_FILES["X_train"])
X_test = pd.read_csv(LOCAL_FILES["X_test"])
y_test = pd.read_csv(LOCAL_FILES["y_test"])

# Load the trained LightGBM model
lgbm_model = joblib.load(LOCAL_FILES["model"])

# Add Fraud column for visualization
X_test['Fraud'] = y_test.values

# Map state numbers to names
state_mapping = {
    1: "Alabama", 2: "Alaska", 3: "Arizona", 4: "Arkansas", 5: "California", 6: "Colorado",
    7: "Connecticut", 8: "Delaware", 9: "Florida", 10: "Georgia", 11: "Hawaii", 12: "Idaho",
    13: "Illinois", 14: "Indiana", 15: "Iowa", 16: "Kansas", 17: "Kentucky", 18: "Louisiana",
    19: "Maine", 20: "Maryland", 21: "Massachusetts", 22: "Michigan", 23: "Minnesota",
    24: "Mississippi", 25: "Missouri", 26: "Montana", 27: "Nebraska", 28: "Nevada",
    29: "New Hampshire", 30: "New Jersey", 31: "New Mexico", 32: "New York", 33: "North Carolina",
    34: "North Dakota", 35: "Ohio", 36: "Oklahoma", 37: "Oregon", 38: "Pennsylvania",
    39: "Rhode Island", 40: "South Carolina", 41: "South Dakota", 42: "Tennessee", 43: "Texas",
    44: "Utah", 45: "Vermont", 46: "Virginia", 47: "Washington", 48: "West Virginia",
    49: "Wisconsin", 50: "Wyoming"
}

# Map states in X_test
X_test['StateName'] = X_test['State'].map(state_mapping)

# Fill missing state names with the most frequent state
most_frequent_state = X_test['StateName'].mode()[0]
X_test['StateName'] = X_test['StateName'].fillna(most_frequent_state)

# Function to predict fraud
def predict_fraud(data):
    predictions = lgbm_model.predict(data)
    probabilities = lgbm_model.predict_proba(data)[:, 1]  # Probability of fraud
    return predictions, probabilities

# Main Streamlit Application
def main():
    st.set_page_config(
        page_title="Fraud Detection Dashboard",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    st.title("üìä Healthcare Provider Fraud Detection Dashboard")
    st.markdown("""
        ## About This Application
        This application is designed to detect potential fraud among healthcare providers based on their claims data.
        It allows users to:
        - Predict whether a selected healthcare provider is involved in fraudulent activities.
        - Explore insights and patterns in the dataset through visualizations.
        - Understand the underlying factors contributing to fraud detection.

        The predictions are powered by a pre-trained **LightGBM model** built on a structured dataset, ensuring accuracy and reliability.
    """)

    # Tabs for different sections
    tabs = st.tabs(["Dataset Summary", "Insights", "Predictions"])

    # Tab 1: Dataset Summary
    with tabs[0]:
        st.header("üìÇ Dataset Summary")

        # Display dataset size
        st.write(f"### Dataset Sizes:")
        st.write(f"- **Training Dataset:** {X_train.shape[0]} rows, {X_train.shape[1]} columns")
        st.write(f"- **Testing Dataset:** {X_test.shape[0]} rows, {X_test.shape[1]} columns")

        # Display column descriptions
        st.write("### Column Descriptions (X_train):")
        for col in X_train.columns:
            st.write(f"- **{col}**: {X_train[col].dtype}, Unique Values: {X_train[col].nunique()}")

        # Display first few rows of datasets
        st.write("### Sample Data from Testing Dataset:")
        st.write(X_test.head())

    # Tab 2: Insights
    with tabs[1]:
        st.header("üìà Insights and Visualizations")

        # Fraud vs. Non-Fraud counts
        st.subheader("1Ô∏è‚É£ Fraud vs. Non-Fraud Counts")
        plt.figure(figsize=(3, 2))
        sns.countplot(x='Fraud', data=X_test, palette='Set2')
        plt.title("Fraud vs. Non-Fraud Counts", fontsize=9)
        plt.xlabel("Fraud (0: Non-Fraud, 1: Fraud)", fontsize=8)
        plt.ylabel("Count", fontsize=8)
        plt.xticks(fontsize=7)
        plt.yticks(fontsize=7)
        st.pyplot(plt)

        # State-wise fraud distribution
        st.subheader("2Ô∏è‚É£ State-wise Fraud Distribution")
        state_fraud = X_test.groupby('StateName')['Fraud'].mean().sort_values(ascending=False)
        plt.figure(figsize=(10, 4))
        state_fraud.plot(kind='bar', color='teal')
        plt.title("State-wise Fraud Distribution", fontsize=12)
        plt.xlabel("State", fontsize=10)
        plt.ylabel("Average Fraud Rate", fontsize=10)
        plt.xticks(fontsize=8, rotation=90)
        plt.yticks(fontsize=8)
        plt.tight_layout()
        st.pyplot(plt)

        # Feature importance
        st.subheader("3Ô∏è‚É£ Feature Importance")
        if hasattr(lgbm_model, 'feature_importances_'):
            feature_importances = pd.DataFrame({
                'Feature': X_train.columns,
                'Importance': lgbm_model.feature_importances_
            }).sort_values(by='Importance', ascending=False)

            plt.figure(figsize=(5, 3))
            sns.barplot(data=feature_importances, x='Importance', y='Feature', palette='viridis')
            plt.title("Feature Importance", fontsize=9)
            plt.xlabel("Importance", fontsize=8)
            plt.ylabel("Feature", fontsize=8)
            plt.xticks(fontsize=7)
            plt.yticks(fontsize=7)
            st.pyplot(plt)

    # Tab 3: Predictions
    with tabs[2]:
        st.header("üîç Predictions")

        provider_id = st.selectbox("Select a Provider from Testing Dataset", X_test.index)
        provider_data = X_test.iloc[[provider_id]].drop(columns=['Fraud', 'StateName'])

        st.write("### Provider Details:")
        st.write(provider_data)

        if st.button("Predict Fraud"):
            prediction, probability = predict_fraud(provider_data)
            fraud_probability = probability[0] * 100
            provider_name = X_test.iloc[provider_id]['Provider']

            if prediction[0] == 1:
                st.success(f"üö© The provider **{provider_name}** is **FRAUD** with a probability of **{fraud_probability:.2f}%**.")
            else:
                st.success(f"‚úÖ The provider **{provider_name}** is **NOT FRAUD** with a probability of **{fraud_probability:.2f}%**.")

if __name__ == "__main__":
    main()

